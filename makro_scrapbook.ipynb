{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test scrape\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import *\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "define_urls() outputs list of urls that need to be scraped\n",
    "used as input to scrape_extract, which scrapes all pages of the url provided\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available(pattern, found):\n",
    "    if re.search(pattern, str(found)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def isPagination(toggle, url, page):\n",
    "    if not toggle:\n",
    "        return url\n",
    "    if toggle:\n",
    "        return f'{url[:-1]}{{{page}}}'\n",
    "\n",
    "def paginationResponse(toggle, url, page):\n",
    "    if toggle:\n",
    "        tmp = f'{isPagination(toggle, url, page)}'\n",
    "        activeUrl = f\"f'{tmp}'\"\n",
    "        return requests.get(eval(activeUrl))\n",
    "    if not toggle:\n",
    "        return requests.get(url)\n",
    "\n",
    "def link_category(df, sub_category):\n",
    "    return df['category'][df['link'] == sub_category].iloc[0]\n",
    "\n",
    "def scrape_extract(urls):\n",
    "    mdf = pd.DataFrame(columns=['date', 'link', 'price', 'name', 'delivery', 'store'])\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        pattern = '.\\d$'\n",
    "        try:\n",
    "            lastPage = int(re.search(pattern, soup.find('div', class_='mak-pagination-new').ul.text)[0])\n",
    "            toggle = True\n",
    "        except:\n",
    "            lastPage = 1\n",
    "            toggle = False\n",
    "\n",
    "        for i in range(0, lastPage):\n",
    "            response = paginationResponse(toggle, url, page=i)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "            ### product and price\n",
    "            result = soup.find_all('div', class_='mak-product-tiles-container__product-tile')\n",
    "            \n",
    "            \n",
    "            priceList = [\"\".join(re.findall('\\d', x.find('p', class_='col-xs-12').text)) for x in result]\n",
    "            nameList = [x.find('a', class_='product-tile-inner__productTitle').span.text for x in result]\n",
    "\n",
    "            # extract in-store and delivery availability \n",
    "            storePattern = 'Store'\n",
    "            deliveryPattern = 'Delivery'\n",
    "            availability = [str(x.find_all('span', {'class' : 'fulfillment'})) for x in result]\n",
    "            storeAvailability = [available(storePattern, x) for x in availability]\n",
    "            deliveryAvailability = [available(deliveryPattern, x) for x in availability]\n",
    "\n",
    "            # extract product page link\n",
    "            link_list = ['www.makro.co.za' + x.find_all('a', class_='product-tile-inner__img', href=True)[0]['href'] for x in result]\n",
    "\n",
    "            # extract rating\n",
    "            # rating = [x.find_all('div', class_='bv_text') for x in result]\n",
    "\n",
    "            df = pd.DataFrame({'date':date.today(), 'link':link_list, 'price':priceList, 'name':nameList, 'delivery':deliveryAvailability, 'store':storeAvailability})        # print(mdf)\n",
    "        mdf = pd.concat([df, mdf])\n",
    "    return mdf\n",
    "\n",
    "def define_urls_makrocoza():\n",
    "    categories = pd.DataFrame(columns=['name', 'link'])\n",
    "    sub_categories = pd.DataFrame(columns=['category', 'name', 'link'])\n",
    "    sub_sub_categories = pd.DataFrame(columns=['category', 'sub_category', 'name', 'link'])\n",
    "\n",
    "    response = requests.get(f\"https://www.makro.co.za\")\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    ### product and price\n",
    "    response = soup.find_all(\"a\", class_='mak-footer-v2__category-name')\n",
    "    names = [x.text.strip() for x in response]\n",
    "    links = [x['href'] for x in response]\n",
    "    categories = pd.DataFrame({'name':names, 'link':links})\n",
    "\n",
    "\n",
    "    for i in tqdm(range(0, len(categories))):\n",
    "        response = requests.get(f\"https://www.makro.co.za/{categories['link'][i]}\")\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        response = soup.find_all(\"div\", class_='col-xs-6 col-sm-3 col-md-2 feature-image-text')\n",
    "\n",
    "        names = [x.text.strip() for x in response]\n",
    "        links = [x.a['href'] for x in response]\n",
    "        tmp = pd.DataFrame({'category':categories['name'][i], 'name':names, 'link':links})\n",
    "        sub_categories = pd.concat([sub_categories, tmp])\n",
    "\n",
    "    sub_categories = sub_categories.reset_index(inplace=False).iloc[:, 1:]\n",
    "\n",
    "    for i in tqdm(range(0, len(sub_categories))):\n",
    "        response = requests.get(f\"https://www.makro.co.za/{sub_categories['link'][i]}\")\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        response = soup.find_all(\"div\", class_='col-xs-6 col-sm-3 col-md-2 feature-image-text')\n",
    "        names = [x.text.strip() for x in response]\n",
    "        links = [x.a['href'] for x in response]\n",
    "\n",
    "        tmp = pd.DataFrame({'category':link_category(sub_categories, sub_categories['link'][i]), 'sub_category':sub_categories['name'][i], 'name':names, 'link':['https://www.makro.co.za' + link for link in links]})\n",
    "        sub_sub_categories = pd.concat([sub_sub_categories, tmp])\n",
    "\n",
    "\n",
    "    sub_sub_categories = sub_sub_categories.reset_index(inplace=False).iloc[:, 1:]\n",
    "    return sub_sub_categories['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regan\\AppData\\Local\\Temp\\ipykernel_12472\\2448202327.py:82: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(0, len(categories))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feea5b22d894318b03a9b20fa96b2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regan\\AppData\\Local\\Temp\\ipykernel_12472\\2448202327.py:96: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(0, len(sub_categories))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0b4bba63154f9694ca01dc50beafb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = scrape_extract(define_urls_makrocoza()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('C:\\\\Users\\\\regan\\\\OneDrive - 22Seven Digital\\\\5-scripts\\\\scrape_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
